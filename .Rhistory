pairs(nt_mtcars, panel = panel.smooth, col =  mtcars$am +2)
install.packages(c("car", "nlme", "Rcpp"))
install.packages(c("car", "nlme", "Rcpp"))
install.packages(c("car", "nlme", "Rcpp"))
install.packages(c("car", "nlme", "Rcpp"))
install.packages(c("car", "nlme", "Rcpp"))
figure1<-ggplot(mtcars,aes(x=factor(am, labels = c("Manual","Auto")),y=mpg,fill=factor(am, labels = c("Manual","Auto"))))
figure1<-figure1+geom_boxplot()
figure1<-figure1+scale_fill_discrete(name = "Transmission Type")
figure1<-figure1 + theme_bw() + xlab("Transmission Type") + ylab("Miles Per Gallon")
figure1
library(ggplot2)
install.packages("ggplot2")
library(ggplot2)
data("mtcars")
head(mtcars)
?mtcars
library(ggplot2)
data("mtcars")
head(mtcars)
nt_mtcars<-subset(mtcars,select = c(1:7))
pairs(nt_mtcars, panel = panel.smooth, col =  mtcars$am +2)
figure1<-ggplot(mtcars,aes(x=factor(am, labels = c("Auto","Manual")),y=mpg,fill=factor(am, labels = c("Auto","Manual"))))
figure1<-figure1+geom_boxplot()
figure1<-figure1+scale_fill_discrete(name = "Transmission Type")
figure1<-figure1 + theme_bw() + xlab("Transmission Type") + ylab("Miles Per Gallon")
figure1
fit1<-lm(mpg ~ factor(am), data = mtcars)
summary(fit1)
fit4<-lm(mpg ~ factor(am) + cyl + hp + wt, data = mtcars)
summary(fit4)
fit6<-lm(mpg ~ factor(am) + cyl + hp + wt + disp +qsec, data = mtcars)
summary(fit6)
anova(fit1,fit4,fit6)
par(mfrow = c(2, 2))
plot(fit4)
x=c(1,2,3)
y=c(2,3,4)
plot(x,y)
plot(x,y,col=2)
plot(x,y,col=3)
summary(fit1)
fit4<-lm(mpg ~ factor(am) + cyl + hp + wt, data = mtcars)
summary(fit4)
fit6<-lm(mpg ~ factor(am) + cyl + hp + wt + disp +qsec, data = mtcars)
summary(fit6)
anova(fit1,fit4,fit6)
confint(fit4)
summary(fit4)
anova(fit1,fit4,fit6)
install.packages("caret")
install.packages("kernlab")
library(kernlab)
data(spam)
install.packages(ISLR)
install.packages("ISLR")
library(ISLR)
data(wage)
data(Wage)
summary(Wage)
library(caret)
install.packages("caret")
install.packages("caret")
library(caret)
inTrain<-createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
install.packages("caret")
install.packages("ggplot2")
install.packages("ISLR")
library(caret)
library(ISLR)
data(Wage)
inTrain<-createDataPartition(y=Wage$wage,p=0.7,list=FALSE)
training<-Wage[inTrain,]
testing<-Wage[-inTrain,]
featurePlot(x=training[,c("age","education","jobclass")],y=training$wage,plot = "pairs")
qplot(age,wage,data=training)
qplot(age,wage,data=training,colour=jobclass)
qplot(age,wage,data=training,colour=education)
qq<-qplot(age,wage,data=training,colour=education)
qq+geom_smooth(method="lm",formula = y~x)
install.packages("Hmisc")
cutWage<-cut2(training$age)
library(Hmisc)
cutWage<-cut2(training$age)
cutWage<-cut2(training$age,g=3)
table(cutWage)
qplot(cutWage,age,data=training,geom = c("boxplot"))
qplot(cutWage,age,data=training,geom = c("boxplot"),fill=cutWage)
qplot(cutWage,age,data=training,geom = "boxplot",fill=cutWage)
qplot(cutWage,age,data=training,geom = c("boxplot","jitter"),fill=cutWage)
table(cutWage,training)
table(cutWage,training$jobclass)
qplot(wage,colour=education,data=training,geom = c("density"))
?Wage
install.packages("kernlab")
library(kernlab)
data(spam)
inTrain<-createDataPartition(y=spam$type,p=0.75,list=FALSE)
training<-spam[inTrain,]
testing<-spam[-inTrain,]
hist(training$capitalAve)
preObj<-preProcess(traning[,-"type"],method=c("center","scale"))
preObj<-preProcess(training[,-"type"],method=c("center","scale"))
preObj<-preProcess(training[,-c("type")],method=c("center","scale"))
preObj<-preProcess(training[,-c58],method=c("center","scale"))
preObj<-preProcess(training[,-58],method=c("center","scale"))
inTrain<-createDataPartition(Wage$wage,p=0.7,list=FALSE)
training<-Wage[inTrain,]
testing<-Wage[-inTrain,]
dummies<-dummyVars(wage~jobclass,data=training)
nsv<-nearZeroVar(training,saveMetrics = TRUE)
nsv
help(package=splines)
?bs()
bsBasis<-bs(training$age,df=3)
library(splines)
bsBasis<-bs(training$age,df=3)
bsBasis
lm1<-lm(wage~bsBasis,data=training)
plot(training$age,training$wage,pch=19,cex=0.5)
points(training$age,predict(lm1,newdata=training),col="red",pch=19,cex=0.5)
lines(training$age,predict(lm1,newdata=training),col="red",pch=19,cex=0.5)
a<-predict(lm1,newdata=training)
rm(list=ls())
data(spam)
inTrain<-createDataPartition(spam$type,p=0.75,list=FALSE)
training<-spam[inTrain,]
testning<-spam[-inTrain,]
M<-abs(cor(training[,-58]))
diag(M)<-0
which(M>0.8,arr.ind = TRUE)
?which
names(training)[32]
names(training)[34]
names(training)[40]
which(M>0.8,arr.ind = F)
which(M>0.8,arr.ind = T)
a<-which(M>0.8,arr.ind = T)
plot(spam[,40],spam[,32])
plot(spam[,40],spam[,34])
plot(spam[,32],spam[,34])
princomp(spam[,c(32,34,40)])
princomp(spam[,c(32,34,40)])$x
princomp(spam[,c(32,34,40)])$x[,1]
a<-princomp(spam[,c(32,34,40)])
a$x
a<-spam[,c(32,34,40)]
b<-princomp(a)
b$x
plot(b$x[,1],b[,2])
plot(b$x[,1],b$x[,2])
b
b$center
b$loadings
b$scores
?princomp
loadings(b$loadings)
b$loadings
b<-prcomp(a)
plot(b$x[,1],b$x[,2])
b$rotation
data(eruption)
data("faithful")
summary(faithful)
View(faithful)
View(faithful)
rm(list=ls())
data("Wage")
head(Wage)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
?preProcess
install.packages("AppliedPredictiveModeling")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
preObj <- preProcess(training[, IL_col_idx], method=c("center", "scale", "pca"), thresh=0.8)
preObj
IL_col_idx <- grep("^[Ii][Ll].*", names(training))
preObj <- preProcess(training[, IL_col_idx], method=c("center", "scale", "pca"), thresh=0.8)
Error in `[.data.frame`(training, , IL_col_idx) :
preObj
View(adData)
names(training)[58]
names(training)[59]
install.packages("rattle")
install.packages("ElemStatLearn")
library(ElemStatLearn)
data("ozone")
head(ozone)
dim(ozone)
View(ozone)
View(ozone)
?bag
?ctreeBag
ctreeBag
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6,
list = FALSE) # 60% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
# 2. Set the seed to 125 and fit a CART model with the rpart method using all predictor variables and default caret settings. (The outcome class is contained in a factor variable called Class with levels "PS" for poorly segmented and "WS" for well segmented.)
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
set.seed(125)
> modFit <- train(Class ~ ., method = "rpart", data = training)
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
install.packages("e1071")
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
install.packages("rattle")
library(rattle)
library(rattle)
install.packages(rpart.plot)
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
install.packages("pgmm")
install.packages("pgmm")
library(pgmm)
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
modolive <- train(Area ~ ., method = "rpart", data = olive)
predict(modolive, newdata = newdata)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass(trainSA$chd, predict(modelSA, newdata = trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
install.packages("randomforest")
install.packages("randomForest")
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
library(randomForest)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
modvowel <- train(y ~ ., data = vowel.train,method="rf",prox=TRUE)
modvowel$varIMP
varIMP(modvowel)
?modvowel$varIMP
modvowel$varIMP
modvowel$varIMP(modvowel)
varImp(modvowel)
importance
importance(modvowel)
importance(modvowel$finalModel)
order(importance(modvowel$finalModel))
order(importance(modvowel$finalModel),decreasing = T)
install.packages("quantMod")
install.packages("quantmod")
install.packages("gbm")
install.packages("lubricate")
install.packages("lubridate")
library(lubridate)
install.packages("forecast")
install.packages("e1071")
install.packages("e1071")
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
library(caret)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_gbm, vowel.test$y)$overall[1]
predDF <- data.frame(pred_rf, pred_gbm, y = vowel.test$y)
sum(pred_rf[predDF$pred_rf == predDF$pred_gbm] ==
predDF$y[predDF$pred_rf == predDF$pred_gbm]) /
sum(predDF$pred_rf == predDF$pred_gbm)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(training)
View(training)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(pred_rf, testing$diagnosis)$overall[1]
confusionMatrix(pred_gbm, testing$diagnosis)$overall[1]
confusionMatrix(pred_lda, testing$diagnosis)$overall[1]
confusionMatrix(combPred, testing$diagnosis)$overall[1]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(223)
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
library(elasticnet)
plot.enet(mod_lasso$finalModel, xvar = "penalty", use.color = TRUE)
setwd("C:/Users/Administrator/OneDrive/Course/pratical machine learning")
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
dat = read.csv("~/gaData.csv")
dat = read.csv("gaData.csv")
raining = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
dim(training$visitsTumblr)
rm(list=ls())
dat = read.csv("~/Desktop/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
dat = read.csv("gaData.csv")
training = dat[year(dat$date) < 2012,]
library(lubridate)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
mod_ts <- bats(tstrain)
fcast <- forecast(mod_ts, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr & testing$visitsTumblr < fcast$upper) /
dim(testing)[1]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
mod_svm <- svm(CompressiveStrength ~ ., data = training)
pred_svm <- predict(mod_svm, testing)
accuracy(pred_svm, testing$CompressiveStrength)
rm(list=ls())
setwd("C:/Users/Administrator/OneDrive/Course/pratical machine learning/Prediction_Assignment_Writeup")
training<-read.csv("pml-training.csv")
testing<-read.csv("pml-testing.csv")
View(testing)
View(training)
View(training)
sum(is.na(training$min_roll_dumbbell))
sum(!is.na(training$min_roll_dumbbell))
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(trainUrl, "training.csv", method="curl")
download.file(testUrl, "testing.csv", method="curl")
training<-read.csv("training.csv")
testing<-read.csv("testing.csv.csv")
?download.file
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(trainUrl, "training.csv", method="auto")
download.file(testUrl, "testing.csv", method="auto")
training<-read.csv("training.csv")
testing<-read.csv("testing.csv.csv")
training<-read.csv("training.csv")
testing<-read.csv("testing.csv")
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if (!file.exists("training.csv"))
download.file(trainUrl, "training.csv", method="auto")
if (!file.exists("testing.csv"))
download.file(testUrl, "testing.csv", method="auto")
training<-read.csv("training.csv")
testing<-read.csv("testing.csv")
library(randomForest)
View(training)
View(training)
duplicated(names(testing))
?duplicated
names(training)
?createDataPartition
set.seed(9527)
inTrain<-createDataPartition(training$classe, p = 0.7, list = FALSE)
testing$classe
names(testing)
trainingNZV <- nearZeroVar(training, saveMetrics=TRUE)
?nearZeroVar
sum(trainingNZV$zeroVar)
sum(trainingNZV$nzv)
training<-training[,!trainingNZV$nzv]
apply(is.na(training),2,sum)
a<-apply(is.na(training),2,sum)
table(a)
b<-is.na(training)
dim(b)
a<-apply(is.na(training),1,sum)
table(a)
dim(a)
length(a)
length(apply(is.na(training),2,sum))
training<-training[,!(nanum/dim(training)>0.8)]
nanum<-apply(is.na(training),2,sum)
training<-training[,!(nanum/dim(training)>0.8)]
View(training)
View(training)
training<-training[,-1]
set.seed(9527)
inTrain<-createDataPartition(training$classe, p = 0.6, list = FALSE)
Mytraining<-training[inTrain,]
Mytesting<-training[-inTrain,]
testing<-testing[,colnames(training)]
testing<-subset(testing,select=colnames(training))
?subset
a<-colnames(training)
testing[,"X"]
testing[,a]
testing[,c(a)]
View(testing)
View(testing)
testing[,c("X","user_name")]
a<-c("X","user_name")
c<-colnames(training)
grep(c,colnames(testing))
grep(c[1],colnames(testing))
grep(c[2],colnames(testing))
grep(c[3],colnames(testing))
grep(c[5],colnames(testing))
?grep
apply(colnames(training),1,grep,x = colnames(testing))
apply(colnames(training),2,grep,x = colnames(testing))
length(colnames(training))
a[3]="as"
for (i in 1:length(colnames(training))){
colindex[i]<-grep(colnames(training)[i],colnames(testing))
}
colindex<-NULL
for (i in 1:length(colnames(training))){
colindex[i]<-grep(colnames(training)[i],colnames(testing))
}
is.na(NULL)
for (i in 1:length(colnames(training))){
temp<-grep(colnames(training)[i],colnames(testing))
if(length(temp)!=0)
colindex[i]<-temp
}
for (i in 1:length(colnames(training))){
temp<-grep(colnames(training)[i],colnames(testing))
if(length(temp)>0)
colindex[i]<-temp
}
testing<-testing[,colindex]
